{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c64048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing relevant libraries\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e032d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBT Account Id and API Key\n",
    "account_id= \"your_account_id\"\n",
    "API_TOKEN = \"your_dbt_api_token\" \n",
    "\n",
    "# Database connection details\n",
    "username = \"your_username\"\n",
    "password = \"your_password\"\n",
    "host = \"your_host\"  # Or your database host\n",
    "port = \"your_post\"  # Default PostgreSQL port\n",
    "database = \"your_database\"\n",
    "schema=\"your_schema\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68fafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your actual API token and endpoint\n",
    "\n",
    "BASE_URL = f\"https://cloud.getdbt.com/api/v2/accounts/{account_id}/runs/\"\n",
    "\n",
    "# Headers for authentication\n",
    "headers = {\n",
    "    \"Authorization\": f\"Token {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "total_runs = requests.get(BASE_URL, headers=headers).json().get(\"extra\")['pagination']['total_count']\n",
    "\n",
    "print(\"Total runs for this dbt account are \", total_runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pagination parameters\n",
    "limit = 100  # Maximum number of records per request\n",
    "total_records = total_runs  # Total number of records\n",
    "records_to_fetch = total_runs\n",
    "\n",
    "# Calculate the starting offset\n",
    "start_offset = total_records - records_to_fetch\n",
    "\n",
    "# Initialize an empty list to store the records\n",
    "last_records = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb69448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Loop through and fetch 100 records at a time until we have all the records\n",
    "offset = start_offset\n",
    "while offset < total_records:\n",
    "    # Make the API request with limit and offset\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    response = requests.get(BASE_URL, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        runs = data.get(\"data\", [])\n",
    "        last_records.extend(runs)\n",
    "\n",
    "        # Increment offset by the limit\n",
    "        offset += limit\n",
    "    else:\n",
    "        print(f\"Failed to fetch data: {response.status_code}, {response.text}\")\n",
    "        break\n",
    "\n",
    "# Convert the results to a pandas DataFrame\n",
    "df = pd.DataFrame(last_records)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2205de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all timestamp columns to datetime\n",
    "dt_columns= ['created_at','updated_at','dequeued_at','started_at','finished_at','last_checked_at',\\\n",
    "              'last_heartbeat_at','should_start_at']\n",
    "for column in dt_columns :\n",
    "    try:\n",
    "        df[column] = pd.to_datetime(df[column])\n",
    "    except Exception:\n",
    "        pass  # Skip non-datetime columns\n",
    "\n",
    "# Define the timezone conversion\n",
    "utc = pytz.utc\n",
    "ist = pytz.timezone(\"Asia/Kolkata\")\n",
    "\n",
    "# Convert all datetime columns from UTC to IST\n",
    "for column in df.select_dtypes(include=['datetime64[ns]']).columns:\n",
    "    df[column] = df[column].dt.tz_localize(utc).dt.tz_convert(ist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "\n",
    "# Create an SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql+psycopg2://{username}:{password}@{host}:{port}/{database}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc8c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('dbt_runs',con=engine, schema=schema, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768da263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
